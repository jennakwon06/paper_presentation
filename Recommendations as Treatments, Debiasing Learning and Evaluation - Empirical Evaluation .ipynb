{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be reproducing the experimental results in \"Recommendations as Treatments: Debiasing Learning and Evaluation\". \n",
    "\n",
    "# Premise\n",
    "## Why debiase learning and evaluation in recommender systems?\n",
    "Recommender systems present sparse data that is prone to selection biases as users are more likely to rate items that they like or know. This means data is MNAR (Missing Not At Random) as observations are conditioned on what we like to optimize (star rating indicating quality of recommendation). MNAR data is a problem as it distorts evaluating rating and recommendation quality estimators. \n",
    "\n",
    "## Framing the problem\n",
    "This paper frames recommender systems as treatments in medical system. Precisely, recommending an item to a user is analogous to giving a new treatment to a patient. This allows us to view recommendars in casual inference setting and \n",
    "to derive a framework for unbiased evaluation and learning with MNAR data. \n",
    "\n",
    "## Contribution of the paper\n",
    "First, the authors demonstrate propensity-weighing techniques to develop unbiased rating and recommendation quality estimators.\n",
    "Secondly, the authors propose Empirical Risk Minimization (ERM) framework and derive a matrix factorization model that can learn under the presence of selection bias in data.\n",
    "Last, the authors explore techniques for estimating propensities in observation settings and demonstrate the robustness of the framework when propensities are misspecified.  \n",
    "\n",
    "# Steps to reproduce\n",
    "6.2) How does sampling bias severity affect evaluation?\n",
    "- Step 1: Prepare synthetic ML100K dataset\n",
    "- Step 2: Prepare ML100K Observation Models\n",
    "- Step 3: Illustrate the effectiveness of unbiased estimators on semi-synthetic dataset and observation models\n",
    "\n",
    "6.3) How does samplig bias severity affect learning?\n",
    "- Step 4: Compare MF-IPS and MF-Naive models\n",
    "\n",
    "6.4) How robust is evaluation and learning to inaccurately learned propensities?\n",
    "- Step 5: Create propensity estimation models\n",
    "- Step 6: Demonstrate performances of propensity estimators and matrix factorizations under observational settings\n",
    "\n",
    "6.5) How do estimators perform on real data?\n",
    "- Step 7: Demonstrate performances of propensity estimators and matrix factorizations with real data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repository structure in /code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# /generated : pickle files that store data between steps to save duplicate computations\n",
    "# /library \n",
    "    # /estimators\n",
    "        # /ips.py\n",
    "        # /naive.py\n",
    "        # /snips.py\n",
    "    # /factorization\n",
    "        # /mf_ips.py\n",
    "        # /mf_naive.py\n",
    "    # /util\n",
    "# /rawdata\n",
    "    # /coat\n",
    "    # /ml-100k\n",
    "# step1.py\n",
    "# step2.py\n",
    "# ..\n",
    "# step7.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does sampling bias affect evaluation?\n",
    "## Step 1) Prepare ML100K semi-synthetic dataset \n",
    "\n",
    "In ML100K dataset, there are 100K ratings for 1683 movies by 944 users. This means the matrix has ~6% of entries filled. To enable ground-truth evaluation against a complete dataset, we synthetically fill in missing entries as demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View underlying data\n",
    "We import raw data (u.data) file in ML100K dataset that contains MNAR ratings for 1683 movies by 944 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1     2     3     4     5     6     7     8     9     10    ...   \\\n",
       "user_id                                                               ...    \n",
       "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...    \n",
       "2          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...    \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "5          4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "6          4.0   NaN   NaN   NaN   NaN   NaN   2.0   4.0   4.0   NaN  ...    \n",
       "7          NaN   NaN   NaN   5.0   NaN   NaN   5.0   5.0   5.0   4.0  ...    \n",
       "8          NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN  ...    \n",
       "9          NaN   NaN   NaN   NaN   NaN   5.0   4.0   NaN   NaN   NaN  ...    \n",
       "10         4.0   NaN   NaN   4.0   NaN   NaN   4.0   NaN   4.0   NaN  ...    \n",
       "\n",
       "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                               \n",
       "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "7          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "8          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "9          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "10         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[10 rows x 1682 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snippet in code/step1.py\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('rawdata/ml-100k/u.data', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1', usecols=[0,1,2])\n",
    "\n",
    "ratings_df = ratings.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "ratings_df[:10] # show top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity :  6.30466936422 %\n"
     ]
    }
   ],
   "source": [
    "# View sparsity \n",
    "print \"Sparsity : \", sum(ratings_df.notnull().sum(axis=1).tolist()) \\\n",
    "                / float((ratings_df.shape[1] * ratings_df.shape[0])) * 100, \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6110 11370 27145 34174 21201]\n"
     ]
    }
   ],
   "source": [
    "# View marginal probabilities of ratings\n",
    "ratings = ratings_df.fillna(0).values\n",
    "hist, binEdges = np.histogram(np.clip(ratings, 0, 5), bins = range(1,7), density = False)\n",
    "print hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing Matrix Factorization model\n",
    "To fill in missing values, we use standard matrix factorization with propensities weighing. We assume rank d-restricted and L2-regularized matrix factorization model with the below training objective (Eq. 14 in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{eqnarray*} argmin(V,W,A) & [ \\sum_{O_{u,i}=1} \\frac{\\delta_{u,i} (Y, V^{T}W + A)}{P_{u,i}} & \n",
       "                    + \\gamma(||V||^{2}_{F} + ||W||^{2}_{F})] \\end{eqnarray*}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex \n",
    "\\begin{eqnarray*} argmin(V,W,A) & [ \\sum_{O_{u,i}=1} \\frac{\\delta_{u,i} (Y, V^{T}W + A)}{P_{u,i}} & \n",
    "                    + \\gamma(||V||^{2}_{F} + ||W||^{2}_{F})] \\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This objective is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(startVector):\n",
    "    \"\"\"\n",
    "    argmin(V,W,A) ( sum of normalized errors (by propensities) between Y and V.T * W + A\n",
    "                    + Reg * (||V||^2F + ||W||^2F)\n",
    "                    V = user matrix\n",
    "                    W = item matrixp\n",
    "                    A = offset terms; user, item, global offsets\n",
    "    \"\"\"\n",
    "    userVectors, itemVectors, userBiases, itemBiases, globalBias = reconstruct2Darrays(startVector)\n",
    "\n",
    "    currentPrediction = np.dot(userVectors, itemVectors.T)\n",
    "    delta = np.subtract(ratings, currentPrediction)\n",
    "    loss = np.square(delta)\n",
    "\n",
    "    normalizedLoss = np.multiply(loss, inversePropensities)  #inversePropensities is defined outside func\n",
    "    objective = np.ma.sum(normalizedLoss, dtype=np.longdouble)\n",
    "\n",
    "    objective += reg * np.sum(np.square(userBiases), dtype = np.longdouble)\n",
    "    objective += reg * np.sum(np.square(itemBiases), dtype = np.longdouble)\n",
    "    objective += reg * np.sum(np.square(globalBias))\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper states using LBFGS solver to minimize this objective. scipy.optimize.minimize library was chosen as an optimization framework as it provides an implementation of LBFGS solver. Below is the full implementation of a matrix factorization model using this library. An instance of this model can be created with a training matrix, regularization parameter, number of dimensions (ranks), and propensities. Training the instantiated model (learning userVecs, itemVecs, userBiases, itemBiases, globalBiases vectors) can be done by calling train() on the instance. Then, prediction matrix can be reconstructed by calling predict_all() after training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\"\"\"\n",
    "Standard matrix factorization with propensity normalization\n",
    "http://activisiongamescience.github.io/2016/01/11/Implicit-Recommender-Systems-Biased-Matrix-Factorization/\n",
    "\"\"\"\n",
    "\n",
    "class MF():\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model to predict empty\n",
    "    entries in a user x item matrix with rating values\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 ranks=40,\n",
    "                 reg=0.0,\n",
    "                 allPropensities=None,\n",
    "                 verbose=False):\n",
    "\n",
    "        # Store Inputs\n",
    "        self.ratings = ratings # masked array with 0 values masked out\n",
    "        self.allPropensities = allPropensities\n",
    "        self.ranks = ranks\n",
    "        self.reg = reg  # regularization factor\n",
    "        self.numUsers, self.numItems = self.ratings.shape \n",
    "\n",
    "        # start vectors and used throughout optimiation\n",
    "        self.userVecs = np.random.normal(size=(self.numUsers, self.ranks))  # 943 X 200\n",
    "        self.itemVecs = np.random.normal(size=(self.numItems, self.ranks))  # 1682 X 200\n",
    "        self.userBias = np.zeros(self.numUsers)  # 943 x 1 - what average rating does user give to all movies?\n",
    "        self.itemBias = np.zeros(self.numItems)  # 1682 x 1\n",
    "        self.globalBias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "        self.resultVectors = None\n",
    "    \n",
    "    def train(self):\n",
    "        numUsers, numItems = self.numUsers, self.numItems\n",
    "        rank = self.ranks\n",
    "        reg = self.reg\n",
    "        ratings = self.ratings\n",
    "        allPropensities = self.allPropensities\n",
    "        invPropensities = np.ma.divide(1.0, allPropensities)\n",
    "        inversePropensities = np.array(invPropensities, dtype = np.longdouble, copy = True)\n",
    "        inversePropensities = np.ma.array(inversePropensities, dtype = np.longdouble, copy = False,\n",
    "                            mask = np.ma.getmask(ratings), fill_value = 0, hard_mask = True)\n",
    "        inversePropensities = np.ma.filled(inversePropensities, 0.0)\n",
    "        ratings = np.ma.filled(ratings, 0)\n",
    "        numUsers, numItems = np.shape(ratings)\n",
    "\n",
    "        def flatten2Darray(user_vectors, item_vectors, userBiases, itemBiases, globalBias):\n",
    "            allUserParams = np.concatenate((user_vectors, userBiases[:, None]), axis = 1) # 943 X 201\n",
    "            allItemParams = np.concatenate((item_vectors, itemBiases[:, None]), axis = 1) # 1682 X 201\n",
    "            allParams = np.concatenate((allUserParams, allItemParams), axis = 0) # (2625, 201)\n",
    "            paramVector = np.reshape(allParams, (numUsers + numItems) * (rank + 1)) # (2625, 201), (1682 + 943 * 201), (527626,)\n",
    "            paramVector = np.concatenate((paramVector, [globalBias]))\n",
    "            return paramVector.astype(np.float)\n",
    "\n",
    "        def reconstruct2Darrays(paramVector):\n",
    "            globalBias = paramVector[-1]\n",
    "            allParams = np.reshape(paramVector[:-1], (numUsers + numItems, rank + 1))\n",
    "            allUserParams = allParams[0:numUsers, :]\n",
    "            allItemParams = allParams[numUsers:, :]\n",
    "            userVectors = (allUserParams[:, 0:-1]).astype(np.longdouble)\n",
    "            userBiases = (allUserParams[:, -1]).astype(np.longdouble)\n",
    "            itemVectors = (allItemParams[:, 0:-1]).astype(np.longdouble)\n",
    "            itemBiases = (allItemParams[:, -1]).astype(np.longdouble)\n",
    "            return userVectors, itemVectors, userBiases, itemBiases, globalBias\n",
    "        \n",
    "        def objective(startVector):\n",
    "            \"\"\"\n",
    "            argmin(V,W,A) ( sum of normalized errors (by propensities) between Y and V.T * W + A\n",
    "                            + Reg * (||V||^2F + ||W||^2F)\n",
    "                            V = user matrix\n",
    "                            W = item matrixp\n",
    "                            A = offset terms; user, item, global offsets\n",
    "            \"\"\"\n",
    "            userVectors, itemVectors, userBiases, itemBiases, globalBias = reconstruct2Darrays(startVector)\n",
    "            \n",
    "            currentPrediction = np.dot(userVectors, itemVectors.T)\n",
    "            delta = np.subtract(ratings, currentPrediction)\n",
    "            loss = np.square(delta)\n",
    "\n",
    "            normalizedLoss = np.multiply(loss, inversePropensities)\n",
    "            objective = np.ma.sum(normalizedLoss, dtype=np.longdouble)\n",
    "\n",
    "            objective += reg * np.sum(np.square(userBiases), dtype = np.longdouble)\n",
    "            objective += reg * np.sum(np.square(itemBiases), dtype = np.longdouble)\n",
    "            objective += reg * np.sum(np.square(globalBias))\n",
    "\n",
    "            return objective\n",
    "\n",
    "        flattenedStartVector = flatten2Darray(self.userVecs, self.itemVecs, self.userBias, self.itemBias, self.globalBias)\n",
    "\n",
    "        print \"- BEGINNING OPTIMIZATION FOR RANK = \" + str(rank) + \"AND L2 REG PARAM = \" + str(reg) + \" -\"\n",
    "\n",
    "        ops = {'maxiter': 50, 'disp': True, 'eps' : 1e0}\n",
    "        result = scipy.optimize.minimize(fun=objective, x0=flattenedStartVector,  # x0 = initial guess\n",
    "                        method = 'L-BFGS-B', tol = 1, jac=None, options = ops)\n",
    "\n",
    "        print \"Did optimizer exit successfully? = \" + str(result['success'])\n",
    "        rUV, rIV, rUB, riB, rgB = reconstruct2Darrays(result['x'])\n",
    "\n",
    "        # store in the object\n",
    "        self.resultVectors = (rUV, rIV, rUB, riB, rgB)\n",
    "\n",
    "    def predict_all(self):\n",
    "        rUV, rIV, rUB, riB, rgB = self.resultVectors\n",
    "        return np.dot(rUV, rIV.T) + rUB[:,None] + riB[None,:] + rgB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this factorization model did not converge after a long time. After profiling, we discovered that scipy.optimize.minimize step takes a very long time to converge for this unconstrained problem. For now, we use an alternative model that uses stochastic gradient function as implemented below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MF():\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model to predict empty\n",
    "    entries in a user x item matrix with rating values\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ratings,\n",
    "                 ranks=40,\n",
    "                 reg=0.0,\n",
    "                 allPropensities=None):\n",
    "\n",
    "        # Store Inputs\n",
    "        self.ratings = np.ma.array(ratings, mask=ratings <= 0)  # masked array with 0 values masked out\n",
    "        self.allPropensities = allPropensities\n",
    "        self.ranks = ranks\n",
    "        self.reg = reg  # regularization factor\n",
    "        self.numUsers, self.numItems = self.ratings.shape\n",
    "        self.validRow, self.validCol = self.ratings.nonzero()\n",
    "        self.numValidEntries = len(self.validRow)\n",
    "\n",
    "        # start vectors and used throughout optimization\n",
    "        self.userVecs = np.random.normal(size=(self.numUsers, self.ranks))  # 943 X 200\n",
    "        self.itemVecs = np.random.normal(size=(self.numItems, self.ranks))  # 1682 X 200\n",
    "        self.userBias = np.zeros(self.numUsers)  # 943 x 1 - what average rating does user give to all movies?\n",
    "        self.itemBias = np.zeros(self.numItems)  # 1682 x 1\n",
    "        self.globalBias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "        self.resultVectors = None\n",
    "\n",
    "    def train(self, numIters, learningRate=1e-4):\n",
    "        for i in range(0, numIters):\n",
    "            print \"Iteration # = \" + str(i)\n",
    "            self.sgd(learningRate)\n",
    "        self.resultVectors = (self.userVecs, self.itemVecs, self.userBias, self.itemBias, self.globalBias)\n",
    "\n",
    "    def sgd(self,learningRate):\n",
    "        np.random.shuffle(np.arange(self.numValidEntries))\n",
    "\n",
    "        for indx in np.arange(self.numValidEntries):\n",
    "\n",
    "            u = self.validRow[indx]\n",
    "            i = self.validCol[indx]\n",
    "            prediction = self.predict(u, i)\n",
    "            e = (self.ratings[u,i] - prediction) # error\n",
    "\n",
    "            # Update biases\n",
    "            self.userBias[u] += learningRate * \\\n",
    "                                (e - self.reg * self.userBias[u])\n",
    "            self.itemBias[i] += learningRate * \\\n",
    "                                (e - self.reg * self.itemBias[i])\n",
    "\n",
    "            # Update latent factors\n",
    "            self.userVecs[u, :] += learningRate * \\\n",
    "                                    (e * self.itemVecs[i, :] -\n",
    "                                     self.reg * self.userVecs[u, :])\n",
    "            self.itemVecs[i, :] += learningRate * \\\n",
    "                                    (e * self.userVecs[u, :] -\n",
    "                                     self.reg * self.itemVecs[i, :])\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        prediction = self.globalBias + self.userBias[u] + self.itemBias[i]\n",
    "        prediction += self.userVecs[u, :].dot(self.itemVecs[i, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def predict_all(self):\n",
    "        rUV, rIV, rUB, riB, rgB = self.resultVectors\n",
    "        return np.dot(rUV, rIV.T) + rUB[:,None] + riB[None,:] + rgB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing hyperparameters and executing model training \n",
    "\n",
    "Using this alternative model, parameter optimization for finding the best combination of latent factor and l2 regularization parameter is implemented. The below method produces all models with all combinations specified by grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateAllModels(latent_factors, l2_lambdas, train_data, test_data):\n",
    "    allModels = []\n",
    "\n",
    "    for latentFactor in latent_factors:\n",
    "        for l2_lambda in l2_lambdas:\n",
    "            print \"Produce model for latent factor = \" + str(latentFactor) + \" and l2 lambda = \" + str(l2_lambda)\n",
    "            model = MF(train_data, ranks=latentFactor, reg=l2_lambda, allPropensities=allPropensities, verbose=True)\n",
    "            model.train(200) # train with 200 iterations\n",
    "            predictions = model.predict_all()\n",
    "            allModels.append((model, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After producing all models, we iterate through and adjust the predicted matrices of the models in order to better match a more realistic distribution [p1, p2, p3, p4, p5] for ratings 1 to 5 (explained in section 6.2). More specifically, we sort the matrices by their scores and assign the bottom p1 fractions of the entries a rating of 1, the next p2 fraction a rating of 2, and so on. After adjusting, we choose the best model by maximizing the 0/1 accuracy of the completed matrix on the test set. Below is a implementation of a method that goes through all generated models, adjusts the predicted matrices, and picks the best model by calculating 0/1 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from library.util import error_measures\n",
    "\n",
    "def obtainBestModel(allModels, train_data, test_data):\n",
    "    # Pick the best model whose adjusted matrix produces the best accuracy error\n",
    "    numRows, numCols = ratings.shape\n",
    "    numEntries = numRows * numCols\n",
    "\n",
    "    # Adjust values to better follow marginal distribution given in @Zemel paper\n",
    "    marginalProbabilities = [0.0611, 0.11370, 0.27145, 0.34174, 0.21201]\n",
    "    cumulativeProbabilities = np.cumsum(marginalProbabilities, dtype=np.longdouble)\n",
    "    cumulativeProbabilities = np.insert(cumulativeProbabilities, 0, 0)  # append 0 in the beginning\n",
    "\n",
    "    bestModel = None\n",
    "    bestModelScore = -10000\n",
    "    finalPredictionMatrix = None\n",
    "\n",
    "    for (model, predictions) in allModels:\n",
    "        print \"\\nTesting first model for rank = \" + str(model.ranks) + \" gamma = \" + str(model.reg)\n",
    "        endpoints = []\n",
    "        sortedPredictions = np.sort(predictions, axis=None)\n",
    "\n",
    "        # indices of cutoff elements\n",
    "        for i in range(0, 5):\n",
    "            ind = int(cumulativeMarginals[i] * numEntries)\n",
    "            endpoints.append(sortedPredictions[ind])\n",
    "\n",
    "        # attach last element of the array\n",
    "        endpoints.append(sortedPredictions[numEntries - 1])\n",
    "\n",
    "        print \"ENDPOINTS \"\n",
    "        print endpoints\n",
    "\n",
    "        # adjust ratings to fall in buckets to better follow marginal probabilities\n",
    "        adjustedMatrix = np.empty((numRows, numCols), dtype=np.int)\n",
    "        for i in range(1, 6):\n",
    "            mask = np.logical_and(predictions >= endpoints[i - 1], predictions <= endpoints[i])\n",
    "            adjustedMatrix[mask] = i\n",
    "\n",
    "        # only compare train and test errors in observed entries\n",
    "        train_mask = train_data != 0\n",
    "        pred_copy_train = np.around(adjustedMatrix[train_mask])\n",
    "        train_copy = train_data[train_mask]\n",
    "\n",
    "        test_mask = test_data != 0\n",
    "        pred_copy_test = np.around(adjustedMatrix[test_mask])\n",
    "        test_copy = test_data[test_mask]\n",
    "\n",
    "        # round all numbers in classification matrix\n",
    "        train_score = error_measures.get_accuracy(pred_copy_train, train_copy)\n",
    "        test_score = error_measures.get_accuracy(pred_copy_test, test_copy)\n",
    "\n",
    "        print \"Train accuracy score = \" + str(train_score) + \"\\tTesting accuracy score = \" + str(test_score)\n",
    "\n",
    "        if test_score > bestModelScore:\n",
    "            bestModel = model\n",
    "            bestModelScore = test_score\n",
    "            finalPredictionMatrix = adjustedMatrix\n",
    "\n",
    "    print \"\\n\\n Best model is with rank = \" + str(bestModel.ranks) + \" and gamma = \" + str(bestModel.reg) \\\n",
    "                + \"with score\" + bestModelScore\n",
    "    print \"--------------- HISTOGRAMS ---------------\"\n",
    "    print np.histogram(finalPredictionMatrix, bins=range(1, 7), density=False)\n",
    "    print np.histogram(finalPredictionMatrix, bins=range(1, 7), density=True)\n",
    "    \n",
    "    return (bestModel, finalPredictionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we demonstrate calling the above two defined methods for generating all models and finding the best model. An additional method for producing 90/10 split is implemented. We train the model on a training set and pick the best model by calculating the best 0/1 accuracy score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing first model for rank = 2 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-6.2124959620452334, 2.1988804979567456, 2.8114930751641776, 3.3828218955113751, 4.0191505873334412, 15.124152440025847]\n",
      "Train accuracy score = 37525Testing accuracy score = 3593\n",
      "Testing first model for rank = 2 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-5.8160408092320921, 2.2497007396749971, 2.8260314516827507, 3.3772764900671914, 4.003684531830582, 13.889093499300042]\n",
      "Train accuracy score = 37561Testing accuracy score = 3597\n",
      "Testing first model for rank = 2 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-9.7018731359211277, 2.2110179072657141, 2.8080677090392427, 3.3831453319001428, 4.0173946795295956, 15.081875612655688]\n",
      "Train accuracy score = 37588Testing accuracy score = 3565\n",
      "Testing first model for rank = 2 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-8.3845810253552298, 2.3574725521937951, 2.8949915159335982, 3.3978735967200113, 3.958828045111948, 12.993049626124014]\n",
      "Train accuracy score = 37667Testing accuracy score = 3601\n",
      "Testing first model for rank = 2 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-4.0085725549896463, 2.9007323802361071, 3.1838028628687556, 3.4528326203720892, 3.7405265816069821, 10.89482311333399]\n",
      "Train accuracy score = 38131Testing accuracy score = 3810\n",
      "Testing first model for rank = 2 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[0.88124561448135807, 3.3146448665476647, 3.3942148567144415, 3.486348266098398, 3.5856194494787816, 6.1061169708274612]\n",
      "Train accuracy score = 36928Testing accuracy score = 3708\n",
      "Testing first model for rank = 2 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.3574799775232029, 3.4655997830161653, 3.4846823658907704, 3.5094285378214169, 3.5367631889091964, 3.6271015830455995]\n",
      "Train accuracy score = 36459Testing accuracy score = 3686\n",
      "Testing first model for rank = 2 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852883695939041, 3.5084637445150055, 3.514215769433346, 3.5203875150767092, 3.5264909513488636, 3.5476109267706559]\n",
      "Train accuracy score = 36346Testing accuracy score = 3703\n",
      "Testing first model for rank = 10 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-15.296221275970456, 0.67350313982468268, 2.1192156074835289, 3.3132150267092246, 4.5640760320619567, 18.872988081484639]\n",
      "Train accuracy score = 35324Testing accuracy score = 3428\n",
      "Testing first model for rank = 10 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-15.995533552325877, 0.66408902816482174, 2.1011875374422493, 3.3091231819038986, 4.5634071715163227, 25.083448990879372]\n",
      "Train accuracy score = 35331Testing accuracy score = 3380\n",
      "Testing first model for rank = 10 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-15.847134758956106, 0.77424745198817435, 2.1587326212876645, 3.3154925925877849, 4.5330036163084744, 19.391360228758966]\n",
      "Train accuracy score = 35633Testing accuracy score = 3476\n",
      "Testing first model for rank = 10 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-12.987998397499368, 0.94414501088747693, 2.291501015594311, 3.3469507694480569, 4.4222393476703727, 20.379212833716871]\n",
      "Train accuracy score = 36156Testing accuracy score = 3557\n",
      "Testing first model for rank = 10 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-10.855989089582664, 2.2903104873736657, 3.0361969169439305, 3.4448114939943775, 3.8418660646505627, 17.346024632503383]\n",
      "Train accuracy score = 38689Testing accuracy score = 3860\n",
      "Testing first model for rank = 10 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[-1.5733872872559789, 3.2863769142174419, 3.3861642010919772, 3.4862347253329675, 3.5924393172600402, 8.5785428058510682]\n",
      "Train accuracy score = 37551Testing accuracy score = 3794\n",
      "Testing first model for rank = 10 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.357478631525288, 3.4655778584717414, 3.4846845721777613, 3.5094534501569319, 3.5367753169756928, 3.6270264981337053]\n",
      "Train accuracy score = 36467Testing accuracy score = 3685\n",
      "Testing first model for rank = 10 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852883830875472, 3.5084638520368343, 3.5142157935624514, 3.5203875102130082, 3.5264908870607821, 3.5476109187267091]\n",
      "Train accuracy score = 36347Testing accuracy score = 3703\n",
      "Testing first model for rank = 20 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-18.655481837873946, -0.68027597904510673, 1.4431150615772035, 3.2476603591986866, 5.1020786031362251, 29.341176766231278]\n",
      "Train accuracy score = 34374Testing accuracy score = 3347\n",
      "Testing first model for rank = 20 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-17.637492350589472, -0.67028455943974707, 1.4569238704539966, 3.2483850837744677, 5.0887110410678984, 26.408781508388358]\n",
      "Train accuracy score = 34447Testing accuracy score = 3403\n",
      "Testing first model for rank = 20 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-19.525367522798966, -0.61537503302034091, 1.4778611702535835, 3.2629417797676794, 5.0688073630265968, 25.215300338770454]\n",
      "Train accuracy score = 34494Testing accuracy score = 3420\n",
      "Testing first model for rank = 20 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-15.739780183731561, -0.25581699266164382, 1.7372717188940496, 3.2974870607296274, 4.840537615967504, 22.368820010855242]\n",
      "Train accuracy score = 34971Testing accuracy score = 3448\n",
      "Testing first model for rank = 20 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-14.126979638739645, 1.7987013666963347, 2.9403580059148693, 3.4426877553373463, 3.9023180249576161, 19.633251107527467]\n",
      "Train accuracy score = 38709Testing accuracy score = 3941\n",
      "Testing first model for rank = 20 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[-2.7612244459589497, 3.2692495916383257, 3.3829670429172145, 3.4861476241700369, 3.5948990049992862, 10.228044163762208]\n",
      "Train accuracy score = 37762Testing accuracy score = 3817\n",
      "Testing first model for rank = 20 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.3574799479400701, 3.4655745375967797, 3.4847038323185386, 3.5094506443727673, 3.5367670167767873, 3.6278136212999663]\n",
      "Train accuracy score = 36458Testing accuracy score = 3687\n",
      "Testing first model for rank = 20 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852883607035428, 3.5084640269717533, 3.514215829031051, 3.520387466344495, 3.5264908832753603, 3.5476109278733152]\n",
      "Train accuracy score = 36347Testing accuracy score = 3703\n",
      "Testing first model for rank = 50 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-26.968919514828102, -3.7698093481374939, -0.20856271921570491, 3.0868950590835782, 6.4807816867813237, 35.732654495284073]\n",
      "Train accuracy score = 34129Testing accuracy score = 3365\n",
      "Testing first model for rank = 50 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-32.548291303872624, -3.7131806323050278, -0.16977262380856084, 3.1035053763863978, 6.4697899235301648, 34.157389143362742]\n",
      "Train accuracy score = 34238Testing accuracy score = 3365\n",
      "Testing first model for rank = 50 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-30.011892861842366, -3.600754067113924, -0.13212780275540226, 3.0997898949897169, 6.414703863885638, 40.982245190202832]\n",
      "Train accuracy score = 34369Testing accuracy score = 3474\n",
      "Testing first model for rank = 50 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-27.584105586891752, -2.8421726325964181, 0.42282638192507882, 3.188449246827239, 5.9233284807967461, 34.583177620275144]\n",
      "Train accuracy score = 34998Testing accuracy score = 3492\n",
      "Testing first model for rank = 50 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-20.037078355261198, 0.77606022346624082, 2.710710615576009, 3.4375577382120923, 4.0239578741454922, 26.11465513705545]\n",
      "Train accuracy score = 38344Testing accuracy score = 3948\n",
      "Testing first model for rank = 50 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[-5.3027141864595979, 3.2398841010144639, 3.3788756262448674, 3.4869556042573446, 3.6000381169380478, 11.54290884367563]\n",
      "Train accuracy score = 38131Testing accuracy score = 3847\n",
      "Testing first model for rank = 50 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.3305998294787984, 3.465502957566843, 3.4846959208585759, 3.5094493033463503, 3.5367716083222867, 3.7135012919906796]\n",
      "Train accuracy score = 36467Testing accuracy score = 3687\n",
      "Testing first model for rank = 50 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852883084371178, 3.5084633278212189, 3.5142156257310413, 3.5203874663449954, 3.5264908190668569, 3.547610889620668]\n",
      "Train accuracy score = 36344Testing accuracy score = 3703\n",
      "Testing first model for rank = 100 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-41.540841735446399, -7.7890630003421535, -2.6005922133769075, 2.8331667221255854, 8.530468185644553, 49.835512623427867]\n",
      "Train accuracy score = 34398Testing accuracy score = 3560\n",
      "Testing first model for rank = 100 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-42.591354943773176, -7.7179779700096454, -2.5575668399309461, 2.8381490031642063, 8.4768014987442104, 47.890969560959299]\n",
      "Train accuracy score = 34484Testing accuracy score = 3503\n",
      "Testing first model for rank = 100 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-38.520998054114429, -7.6531982343684071, -2.4895466833663673, 2.8586673001700076, 8.4215906892769397, 45.821797948287028]\n",
      "Train accuracy score = 34702Testing accuracy score = 3555\n",
      "Testing first model for rank = 100 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-44.132181229244914, -6.2601685034145156, -1.4427488825469479, 3.0201140077159634, 7.4968012787667462, 46.35944000266322]\n",
      "Train accuracy score = 35467Testing accuracy score = 3645\n",
      "Testing first model for rank = 100 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-27.418416023148033, -0.40441097524770964, 2.4231175639991953, 3.4359871924911514, 4.1892002128762176, 35.840758989420905]\n",
      "Train accuracy score = 38136Testing accuracy score = 4061\n",
      "Testing first model for rank = 100 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[-7.6039369293517929, 3.1988822500179261, 3.3747979395524004, 3.4867763880399534, 3.6028112032906763, 18.195529130635549]\n",
      "Train accuracy score = 38350Testing accuracy score = 3901\n",
      "Testing first model for rank = 100 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.306344260269511, 3.4654283647428348, 3.4846954196893649, 3.5094869270725821, 3.5368410131249624, 3.6750881866746306]\n",
      "Train accuracy score = 36505Testing accuracy score = 3696\n",
      "Testing first model for rank = 100 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852883901824518, 3.5084630913003632, 3.5142159584481223, 3.5203873630769027, 3.5264908383494742, 3.5476109777427136]\n",
      "Train accuracy score = 36344Testing accuracy score = 3703\n",
      "Testing first model for rank = 200 gamma = 0.0001\n",
      "CHECK ENDPOINTS\n",
      "[-59.684819325490686, -14.301232759731555, -6.6113888680339929, 2.4759788026027731, 12.045344687348136, 69.632795124056116]\n",
      "Train accuracy score = 33256Testing accuracy score = 3327\n",
      "Testing first model for rank = 200 gamma = 0.001\n",
      "CHECK ENDPOINTS\n",
      "[-61.046043978649834, -14.296500783166508, -6.6050379980942093, 2.4713259691607474, 12.032080895600847, 69.551347956500223]\n",
      "Train accuracy score = 33268Testing accuracy score = 3281\n",
      "Testing first model for rank = 200 gamma = 0.01\n",
      "CHECK ENDPOINTS\n",
      "[-67.979204244280069, -13.984336928063563, -6.4160183607118793, 2.4838250951691156, 11.830422696839594, 65.981592798419726]\n",
      "Train accuracy score = 33192Testing accuracy score = 3285\n",
      "Testing first model for rank = 200 gamma = 0.1\n",
      "CHECK ENDPOINTS\n",
      "[-52.15750287340682, -11.32599244650353, -4.4337346900059824, 2.7425350562767083, 10.055940135535268, 65.039358340092662]\n",
      "Train accuracy score = 34152Testing accuracy score = 3388\n",
      "Testing first model for rank = 200 gamma = 1\n",
      "CHECK ENDPOINTS\n",
      "[-40.470125494414461, -2.1018915317241533, 1.9685706233051095, 3.4307288208958568, 4.4809544583653489, 48.024459272132425]\n",
      "Train accuracy score = 39006Testing accuracy score = 4195\n",
      "Testing first model for rank = 200 gamma = 5\n",
      "CHECK ENDPOINTS\n",
      "[-14.535944479689867, 3.1309319003207028, 3.3714362091516792, 3.4878469919603909, 3.6067042185730105, 22.377625767338479]\n",
      "Train accuracy score = 38554Testing accuracy score = 3937\n",
      "Testing first model for rank = 200 gamma = 25\n",
      "CHECK ENDPOINTS\n",
      "[3.2492063261820965, 3.4653756176434616, 3.484695564443776, 3.5094962635360192, 3.5368656290601885, 3.8387548941541607]\n",
      "Train accuracy score = 36516Testing accuracy score = 3693\n",
      "Testing first model for rank = 200 gamma = 125\n",
      "CHECK ENDPOINTS\n",
      "[3.4852884400196622, 3.5084634374876695, 3.5142160735422356, 3.5203876538146615, 3.5264910124587314, 3.5476147555084743]\n",
      "Train accuracy score = 36345Testing accuracy score = 3702\n",
      "Best model is with rank = 200 and gamma = 1\n",
      "\n",
      "--------------- HISTOGRAMS ---------------\n",
      "(array([ 96912, 180342, 430554, 542043, 336275]), array([1, 2, 3, 4, 5, 6]))\n",
      "(array([ 0.06109981,  0.11369967,  0.27145006,  0.34174019,  0.21201027]), array([1, 2, 3, 4, 5, 6]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 3, ..., 3, 4, 4],\n",
       "       [4, 4, 4, ..., 1, 5, 3],\n",
       "       [4, 3, 3, ..., 5, 1, 5],\n",
       "       ..., \n",
       "       [4, 4, 3, ..., 2, 5, 5],\n",
       "       [4, 4, 4, ..., 5, 4, 2],\n",
       "       [4, 3, 4, ..., 4, 3, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def train_test_split(ratings):\n",
    "    \"\"\"\n",
    "    produce a 90/10 train test split and assert they are disjoint\n",
    "    \"\"\"\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in xrange(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0],\n",
    "                                        size=10,\n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # unknown values are filled with 0\n",
    "    train = np.ma.array(train, mask = train <= 0, fill_value = 0, hard_mask = True, dtype=np.int, copy=False)\n",
    "    test = np.ma.array(test, mask = test <= 0, fill_value = 0, hard_mask = True, dtype=np.int, copy=False) \n",
    "\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((np.ma.filled(train, fill_value=0) * np.ma.filled(test, fill_value=0)) == 0))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('rawdata/ml-100k/u.data', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1', usecols=[0,1,2])\n",
    "\n",
    "ratings_df = ratings.pivot(index='user_id', columns='movie_id', values='rating')\n",
    "ratings_df[:10] # show top 10\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "train_data, test_data = train_test_split(ratings)\n",
    "\n",
    "# use a pre-generated file with all models \n",
    "prevGeneratedAllModelsPath = \"generated/step1_allModels_MF_Naive_2.pkl\"\n",
    "\n",
    "allModels = []\n",
    "\n",
    "# CHECK IF ALL MODEL FILES HAVE BEEN GENERATED\n",
    "if os.path.exists(prevGeneratedAllModelsPath):\n",
    "    g = open(prevGeneratedAllModelsPath, 'rb')\n",
    "    allModels = pickle.load(g)\n",
    "    g.close()\n",
    "else:\n",
    "    latent_factors = [200]\n",
    "    l2_lambdas = [1, 5, 25, 125]\n",
    "    allModels = generateAllModels(latent_factors, l2_lambdas, train_data, test_data)\n",
    "\n",
    "(bestModel, ML100K_syntheticMatrix) = obtainBestModel(allModels, train_data, test_data)\n",
    "\n",
    "ML100K_syntheticMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Prepare ML100K observation models\n",
    "\n",
    "Now that we have a synthetic data set, we can create different observation models for varying sampling bias. Comparison amongst these models will allow us to observe how unbiased and biased performance estimators behave with increasing level of sampling bias. Unbiased estimators incorporate propensities while biased estimators do not. We will observe whether unbiased estimators produce values that are closer to values of true performance than biased estimators\n",
    "\n",
    "Different observation models are created by varying values of propensities and marginal probabilities of ratings. We experimentally control the propensity by the below rules. \n",
    "    - propensity = k if rating = 4 & 5\n",
    "    - propensity = k* alpha^(4-r) for rating r < 4\n",
    "    - for each alpha, set k so that the expected # ratings = 5% of the entire matrix\n",
    "    \n",
    "Marginal probabilities and propensities are related by Naive Bayes equation below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{eqnarray*} (1)  P(O_{u,i} = 1| Y_{u,i} = r) = \\frac{ (2)  p(Y = r | O = 1) \\cdot (3)  P(O = 1)}{ (4)  p(Y = r)}\n",
       "\\end{eqnarray*}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{eqnarray*} (1)  P(O_{u,i} = 1| Y_{u,i} = r) = \\frac{ (2)  p(Y = r | O = 1) \\cdot (3)  P(O = 1)}{ (4)  p(Y = r)}\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term (1) describes propensities of ratings and (2) describes marginal probabiliteis of ratings. Term (3) and (4) can be estimated by counting the number of observed values and rankings. Calculations for propensities are implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "    In all methods, we assume iid data which allows us to work with naive bayes equation.\n",
    "    Prop(Ou,i = 1 | Yu,i = r) = Q(Y = r | O = 1) * P(O = 1) /\n",
    "                                            P (Y = r)\n",
    "    Prop = propensity\n",
    "    Q = marginal probability\n",
    "\"\"\"\n",
    "\n",
    "def generatePropensityPerRating(observedRatings, ratingMarginals):\n",
    "    \"\"\"\n",
    "        Calculate Prop(Ou,i = 1 | Yu,i = r) given an observation matrix and Q(Y = r | O = 1)\n",
    "    \"\"\"\n",
    "    numObservations = np.ma.count(observedRatings)\n",
    "    numUsers, numItems = np.shape(observedRatings)\n",
    "    scale = numUsers * numItems\n",
    "\n",
    "    observedRatings = np.ma.compressed(observedRatings)    \n",
    "    observationProbability = 1.0 * numObservations / scale\n",
    "    histogram = np.bincount(observedRatings, minlength = 6)[1:]\n",
    "    probabilisticHistogram = 1.0 * (histogram) / numObservations\n",
    "\n",
    "    propensityPerRating = observationProbability * np.divide(probabilisticHistogram, ratingMarginals)\n",
    "    propensityPerRating = np.clip(propensityPerRating, a_min = 0, a_max = 1)\n",
    "\n",
    "    return propensityPerRating\n",
    "\n",
    "def generateMarginalProbabilities(observedRatings, propensityPerRating):\n",
    "    \"\"\"\n",
    "        Calculate Q(Y = r | O = 1) given an observation matrix and Prop(Ou,i = 1 | Yu,i = r)\n",
    "    \"\"\"\n",
    "    allPropensities = generateAllPropensities(propensityPerRating, observedRatings)\n",
    "    observedRatings = generatePartiallyObservedRatings(observedRatings, allPropensities)\n",
    "    observedRatings = np.ma.compressed(observedRatings)\n",
    "    totalRatings = float(len(observedRatings.ravel()))\n",
    "    marginals = [x / totalRatings for x in np.bincount(observedRatings.ravel(), minlength=6)[1:]]\n",
    "    return marginals\n",
    "\n",
    "\n",
    "def generatePropensitiesPerRatingWithAlpha(completeMatrix, ratingsMarginal, alpha, sparsity):\n",
    "    \"\"\"\n",
    "        Generate propensity per rating with varying alpha values\n",
    "        For each alpha, set k so that expected number of rating is 5% of the entire matrix.\n",
    "        For ratings r < 4, the corresponding propensity is k * a4-r.\n",
    "        For ratings r = 4 & 5, the propensity is equal to k\n",
    "\n",
    "    \"\"\"\n",
    "    numRatings = 5\n",
    "    numUsers, numItems = completeMatrix.shape\n",
    "    ratingDistribution = [x * (numUsers * numItems) for x in ratingsMarginal]\n",
    "\n",
    "    # Set rating propensities\n",
    "    ratingPropensities = np.zeros(numRatings, dtype=np.longdouble)\n",
    "    factor = 1.0\n",
    "    for i in range(5):\n",
    "        ratingPropensities[numRatings - i - 1] = factor\n",
    "        if i != 0: factor *= alpha\n",
    "\n",
    "    # ratingPropensities contain [alpha^3, alpha^2, alpha, 1, 1]]\n",
    "    #     Prop(Ou,i = 1 | Yu,i = r) = Q(Y = r | O = 1) * P(O = 1) /\n",
    "    #                                         P (Y = r)\n",
    "    numObservations = sparsity * numUsers * numItems\n",
    "    expectedObservations = np.dot(ratingDistribution, ratingPropensities)\n",
    "    rightSide = numObservations * 1.0 / expectedObservations\n",
    "    ratingPropensities = np.clip(rightSide * ratingPropensities, a_min = 0, a_max = 1)\n",
    "\n",
    "    return ratingPropensities\n",
    "\n",
    "def generateAllPropensities(propensityPerRating, data_matrix, data_disjoint_matrix=None):\n",
    "    allPropensities = np.zeros(np.shape(data_matrix), dtype=np.longdouble)\n",
    "\n",
    "    for ind in range(1, 6):\n",
    "        allPropensities[data_matrix == ind] = propensityPerRating[ind-1]\n",
    "        if data_disjoint_matrix is not None:\n",
    "            allPropensities[data_disjoint_matrix == ind] = propensityPerRating[ind-1]\n",
    "\n",
    "    allPropensities = np.ma.array(allPropensities, dtype=np.longdouble, copy=False,\n",
    "                        mask=allPropensities <= 0, fill_value=1, hard_mask=True)\n",
    "\n",
    "    return allPropensities\n",
    "\n",
    "\n",
    "def generatePartiallyObservedRatings(complete_matrix, propensities):\n",
    "    # generates randomly observed ratings with propensities\n",
    "    numUsers, numItems = np.shape(complete_matrix)\n",
    "    randomllyGeneratedRatings = np.random.random((numUsers, numItems))\n",
    "    observedRatings = np.ma.array(complete_matrix, dtype=np.int, copy=True,\n",
    "                            mask=randomllyGeneratedRatings >= propensities, fill_value=0, hard_mask = True)\n",
    "    return observedRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use above methods to see how we can vary observation models with varying degrees of selection bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal Probabilities for alpha = 0\n",
      "[0.0, 0.0, 0.0, 0.61726815550460457, 0.38273184449539543] \n",
      "\n",
      "Marginal Probabilities for alpha = 0.25\n",
      "[0.0018834058044291638, 0.011199312367276773, 0.10712660531904136, 0.54330569319445854, 0.33648498331479421] \n",
      "\n",
      "Marginal Probabilities for alpha = 0.5\n",
      "[0.011258034661561672, 0.038781900934366162, 0.18746909745553203, 0.47249515067763731, 0.28999581627090282] \n",
      "\n",
      "Marginal Probabilities for alpha = 0.75\n",
      "[0.030796370967741935, 0.076953124999999997, 0.23907510080645161, 0.40287298387096776, 0.25030241935483871] \n",
      "\n",
      "Marginal Probabilities for alpha = 1.0\n",
      "[0.062048807529008605, 0.11440918196364003, 0.27243521096594558, 0.33937233064140199, 0.21173446890000377] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from library.util.propensity import *\n",
    "\n",
    "\"\"\"\n",
    "Generate observation models for varying degrees of alpha\n",
    "\n",
    "\"\"\"\n",
    "g = open(\"generated/step1_bestModel_Naive_2.pkl\", 'rb')\n",
    "(bestModel, ML100K_syntheticMatrix) = pickle.load(g)\n",
    "g.close()\n",
    "\n",
    "# generate observation models for varying alphas\n",
    "alphas = [0, 0.25, 0.5, 0.75, 1.00]\n",
    "ratingsMarginal = [0.0611, 0.11370, 0.27145, 0.34174, 0.21201]\n",
    "observationModels = []\n",
    "for alpha in alphas:\n",
    "    propensitiesPerRating = generatePropensitiesPerRatingWithAlpha(ML100K_syntheticMatrix, ratingsMarginal, alpha, 0.05)\n",
    "    marginalProps = generateMarginalProbabilities(ML100K_syntheticMatrix, propensitiesPerRating)\n",
    "    allPropensities = generateAllPropensities(propensitiesPerRating, ML100K_syntheticMatrix)\n",
    "    observedRatings = generatePartiallyObservedRatings(ML100K_syntheticMatrix, allPropensities)\n",
    "    dict = {\"alpha\": alpha, \"propsPerRating\": propensitiesPerRating,\n",
    "            \"marginalProbs\": marginalProps, \"observedRatings\": observedRatings}\n",
    "    observationModels.append(dict)\n",
    "\n",
    "    print \"Marginal Probabilities for alpha = \" + str(alpha)\n",
    "    print marginalProps, \"\\n\"\n",
    "\n",
    "g = open(\"generated/step2_observationModels_Naive_2.pkl\", 'wb')\n",
    "pickle.dump(observationModels, g, -1)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Illustrate the effectiveness of unbiased estimators on semi-synthetic dataset and observation models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we compare how the estimators perform against these observation models. Below is my implementation of estimators.\n",
    "Among these, IPS and SNIPS estimators incorporate propensities while naive estimator does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_naive(pred, actual, func='mse'):\n",
    "    \"\"\"\n",
    "    Naive prediction accuracy estimator for estimation\n",
    "    between a prediction matrix and a partially complete true ratings matrix\n",
    "\n",
    "    It uses average error over observed entries:\n",
    "    Rnaive (Ypred) = (1 / # Observations) * sum of errors over observed entries\n",
    "\n",
    "    \"\"\"\n",
    "    pred = np.ma.compressed(pred[np.invert(actual.mask)])\n",
    "    actual = np.ma.compressed(actual)\n",
    "    delta = np.ma.subtract(pred, actual)  # subtraction applied for known entries only\n",
    "\n",
    "    if func == 'mse':\n",
    "        delta = np.square(delta)\n",
    "    elif func == 'mae':\n",
    "        delta = np.ma.abs(delta)\n",
    "    elif func == 'rmse':\n",
    "        delta = np.sqrt(np.square(delta))\n",
    "\n",
    "    sum_errors = np.ma.sum(delta, dtype=np.longdouble)\n",
    "    score = sum_errors / (len(pred))\n",
    "\n",
    "    return score\n",
    "\n",
    "def estimate_ips(pred, actual, propsPerRating, func='mae'):\n",
    "    \"\"\"\n",
    "    Inverse-Propensity-Scoring estimator\n",
    "    \"\"\"\n",
    "    I, U = pred.shape\n",
    "\n",
    "    pred = np.ma.compressed(pred[np.invert(actual.mask)])\n",
    "    actual = np.ma.compressed(actual)\n",
    "    delta = np.ma.subtract(pred, actual)  # subtraction applied for known entries only\n",
    "\n",
    "    allPropensities = generateAllPropensities(propsPerRating, actual)\n",
    "\n",
    "    if func == 'mse':\n",
    "        delta = np.square(delta)\n",
    "    elif func == 'mae':\n",
    "        delta = np.ma.abs(delta)\n",
    "    elif func == 'rmse':\n",
    "        delta = np.sqrt(np.square(delta))\n",
    "\n",
    "    errors = np.ma.multiply(delta, np.reciprocal(allPropensities))\n",
    "    sum_errors = np.ma.sum(errors, dtype=np.longdouble)\n",
    "    score = sum_errors / (U * I)\n",
    "\n",
    "    return score\n",
    "\n",
    "def estimate_snips(pred, actual, propsPerRating, func='mse'):\n",
    "    \"\"\"\n",
    "    Self-Normalized-Inverse-Scoring-Estimator\n",
    "    \"\"\"\n",
    "    # for all known entries, calculate delta\n",
    "    pred = np.ma.compressed(pred[np.invert(actual.mask)])\n",
    "    actual = np.ma.compressed(actual)\n",
    "\n",
    "    delta = np.ma.subtract(pred, actual)\n",
    "    allPropensities = generateAllPropensities(propsPerRating, actual)\n",
    "\n",
    "    if func == 'mse':\n",
    "        delta = np.square(delta)\n",
    "    elif func == 'mae':\n",
    "        delta = np.ma.abs(delta)\n",
    "    elif func == 'rmse':\n",
    "        delta = np.sqrt(np.square(delta))\n",
    "\n",
    "    errors = np.ma.multiply(delta, np.reciprocal(allPropensities))\n",
    "    sum_errors = np.ma.sum(errors, dtype=np.longdouble)\n",
    "    sum_normalizers = np.ma.sum(np.reciprocal(allPropensities), dtype=np.longdouble)\n",
    "    score = sum_errors / sum_normalizers\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure how these estimators perform with different observation models on various prediction matrices, we curate 4 different prediction matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createPredictionMatrices(data_ML100K_synthetic):\n",
    "    recOnes = createRecOneMatrix(data_ML100K_synthetic)\n",
    "    recFours = createRecFourMatrix(data_ML100K_synthetic)\n",
    "    rotate = createRotateMatrix(data_ML100K_synthetic)\n",
    "    coarsened = createCoarsenedMatrix(data_ML100K_synthetic)\n",
    "    # skewed = createSkewedMatrix(data_ML100K_synthetic)\n",
    "    return recOnes, recFours, rotate, coarsened\n",
    "    \n",
    "\n",
    "def createRecOneMatrix(actual):\n",
    "    predictedRatings = actual.copy()\n",
    "    numFiveStars = (actual == 5).sum()\n",
    "\n",
    "    oneIndxRows, oneIndxCols = np.where(actual == 1)\n",
    "    numOneStars = np.shape(oneIndxRows)[0]\n",
    "    numFlippedRatings = min(numFiveStars, numOneStars)\n",
    "\n",
    "    randomSubset = np.random.choice(numOneStars, size=numFlippedRatings, replace=False)\n",
    "    flipIndices = (oneIndxRows[randomSubset], oneIndxCols[randomSubset])\n",
    "\n",
    "    predictedRatings[flipIndices] = 5\n",
    "\n",
    "    print \"REC_ONES\", \\\n",
    "        \"Actual \\t\", np.bincount(actual.ravel(), minlength = 6)[1:],\\\n",
    "        \"Modified \\t \", np.bincount(predictedRatings.ravel(), minlength = 6)[1:]\n",
    "\n",
    "    return predictedRatings\n",
    "\n",
    "\n",
    "def createRecFourMatrix(actual):\n",
    "    predictedRatings = actual.copy()\n",
    "    numFiveStars = (actual == 5).sum()\n",
    "\n",
    "    fourIndxRows, fourIndxCols = np.where(actual == 4)\n",
    "    numFourStars = np.shape(fourIndxRows)[0]\n",
    "    numFlippedRatings = min(numFiveStars, numFourStars)\n",
    "\n",
    "    randomSubset = np.random.choice(numFourStars, size = numFlippedRatings, replace = False)\n",
    "    flipIndices = (fourIndxRows[randomSubset], fourIndxCols[randomSubset])\n",
    "\n",
    "    predictedRatings[flipIndices] = 5\n",
    "\n",
    "    print \"REC_FOURS\", \\\n",
    "        \"Actual \\t\", np.bincount(actual.ravel(), minlength = 6)[1:],\\\n",
    "        \"Modified \\t \", np.bincount(predictedRatings.ravel(), minlength = 6)[1:]\n",
    "\n",
    "    return predictedRatings\n",
    "\n",
    "\n",
    "def createRotateMatrix(actual):\n",
    "    predictedRatings = actual.copy()\n",
    "    predictedRatings = predictedRatings - 1\n",
    "    predictedRatings[predictedRatings == 0] = 5\n",
    "\n",
    "    print \"ROTATE\", \\\n",
    "        \"Actual \\t\\t\", np.bincount(actual.ravel(), minlength = 6)[1:],\\\n",
    "        \"Modified \\t \", np.bincount(predictedRatings.ravel(), minlength = 6)[1:]\n",
    "\n",
    "    return predictedRatings\n",
    "\n",
    "\n",
    "def createCoarsenedMatrix(actual):\n",
    "    predictedRatings = actual.copy()\n",
    "    predictedRatings[predictedRatings <= 3] = 3\n",
    "    predictedRatings[predictedRatings >= 4] = 4\n",
    "\n",
    "    print \"COARSENED\", \\\n",
    "        \"Actual \\t\", np.bincount(actual.ravel(), minlength = 6)[1:],\\\n",
    "        \"Modified \\t \", np.bincount(predictedRatings.ravel(), minlength = 6)[1:]\n",
    "\n",
    "    return predictedRatings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REC_ONES Actual \t[ 96912 180342 430554 542043 336275] Modified \t  [     0 180342 430554 542043 433187]\n",
      "REC_FOURS Actual \t[ 96912 180342 430554 542043 336275] Modified \t  [ 96912 180342 430554 205768 672550]\n",
      "ROTATE Actual \t\t[ 96912 180342 430554 542043 336275] Modified \t  [180342 430554 542043 336275  96912]\n",
      "COARSENED Actual \t[ 96912 180342 430554 542043 336275] Modified \t  [     0      0 707808 878318      0]\n"
     ]
    }
   ],
   "source": [
    "# Create prediction matrices\n",
    "g = open(\"generated/step1_bestModel_naive_2.pkl\", 'rb')\n",
    "bestModel, data_ML100K_complete = pickle.load(g)\n",
    "g.close()\n",
    "\n",
    "Y_Rec_Ones, Y_Rec_Fours, Y_Rotate, Y_Coarsened = createPredictionMatrices(data_ML100K_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with these prediction matrices, we show how estimators perform when alpha = 0.25. We attempt to recreate Table 1. in 3.4 of the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[['', 'Truth', 'IPS', 'SNIPS', 'Naive'],\n",
      "        ['REC_ONES', '0.24439924697', '0.954526567621', '0.955052073817',\n",
      "         '0.667621595699'],\n",
      "        ['REC_FOURS', '0.212010269045', '1.16096047483', '1.16159963139',\n",
      "         '1.05730836215'],\n",
      "        ['ROTATE', '1.18329943523', '1.37095933681', '1.3717141064',\n",
      "         '1.42532623236'],\n",
      "        ['COARSENED', '0.447909560779', '0.851778060192', '0.852246999102',\n",
      "         '0.717913122492']]], \n",
      "      dtype='|S14')\n"
     ]
    }
   ],
   "source": [
    "from library.estimators import ips\n",
    "from library.estimators import naive\n",
    "from library.estimators import snips\n",
    "import pprint\n",
    "\n",
    "# Create list of prediction matrices\n",
    "pred_matrices = [('REC_ONES', Y_Rec_Ones),\n",
    "                 ('REC_FOURS', Y_Rec_Fours),\n",
    "                 ('ROTATE', Y_Rotate),\n",
    "                 ('COARSENED', Y_Coarsened)]\n",
    "                 # ('SKEWED', Y_Skewed),\n",
    "\n",
    "estimators = ['Truth', 'IPS', 'SNIPS', 'Naive']\n",
    "measures = ['mae']  # TODO implement DC@50\n",
    "\n",
    "\n",
    "# load observation models\n",
    "g = open(\"generated/step2_observationModels.pkl\", 'rb')\n",
    "observationModels = pickle.load(g)\n",
    "g.close()\n",
    "\n",
    "# look up 0.25 in observation models\n",
    "observationModel25 = (item for item in observationModels if item[\"alpha\"] == 0.25).next()\n",
    "propensitiesPerRating25 = observationModel25[\"propsPerRating\"]\n",
    "observedRatings25 = observationModel25[\"observedRatings\"]\n",
    "\n",
    "step3_data = []\n",
    "for measure in measures:\n",
    "    rowCols = []\n",
    "    for pred in pred_matrices:\n",
    "        # for estimator in estimators:\n",
    "        list = []\n",
    "        for estimator in estimators:\n",
    "            func = None\n",
    "            mean = 0\n",
    "\n",
    "            if measure == 'mae':\n",
    "                func = error_measures.get_mae\n",
    "            elif measure == 'mse':\n",
    "                func = error_measures.get_mse\n",
    "            \n",
    "            trueError = func(pred[1], data_ML100K_complete)\n",
    "\n",
    "            if estimator == 'Truth':\n",
    "                mean = trueError\n",
    "            elif estimator == 'IPS':\n",
    "                mean = ips.estimate_ips(pred[1], observedRatings25, propensitiesPerRating25, func=measure)\n",
    "            elif estimator == 'SNIPS':\n",
    "                mean = snips.estimate_snips(pred[1], observedRatings25, propensitiesPerRating25, func=measure)\n",
    "            elif estimator == 'Naive':\n",
    "                mean = naive.estimate_naive(pred[1], observedRatings25, func=measure)\n",
    "\n",
    "            meanAndErr = str(mean)\n",
    "            list.append(meanAndErr)\n",
    "\n",
    "        list.insert(0, pred[0])  # attach name\n",
    "        rowCols.append(list)\n",
    "\n",
    "    rowCols = np.asarray(rowCols)\n",
    "    estimators.insert(0, '')\n",
    "    rowCols = np.asarray(np.vstack((estimators, rowCols)))  # attach labels\n",
    "    step3_data.append(rowCols)\n",
    "    estimators.remove('')\n",
    "\n",
    "step3_data = np.asarray(step3_data)\n",
    "pp = pprint.PrettyPrinter(width=1000)\n",
    "pp.pprint(step3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLOT VALUES FOR ALL ALPHAS\n",
    "\n",
    "# generate observation models for varying alphas\n",
    "alphas = [0, 0.25, 0.5, 0.75, 1.00]\n",
    "ratingsMarginal = [0.0611, 0.11370, 0.27145, 0.34174, 0.21201]\n",
    "observationModels = []\n",
    "for alpha in alphas:\n",
    "    propensitiesPerRating = generatePropensitiesPerRatingWithAlpha(ML100K_syntheticMatrix, ratingsMarginal, alpha, 0.05)\n",
    "    marginalProps = generateMarginalProbabilities(ML100K_syntheticMatrix, propensitiesPerRating)\n",
    "    allPropensities = generateAllPropensities(propensitiesPerRating, ML100K_syntheticMatrix)\n",
    "    observedRatings = generateObservedRatings(ML100K_syntheticMatrix, allPropensities)\n",
    "    dict = {\"alpha\": alpha, \"propsPerRating\": propensitiesPerRating, \"marginalProbs\": marginalProps, \"observedRatings\": observedRatings}\n",
    "    observationModels.append(dict)\n",
    "\n",
    "    print \"Marginal Probabilities for alpha = \" + str(alpha)\n",
    "    print marginalProps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5) Explore how sampling bias severity affects learning (Section 6.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6) Create propensity estimation model for observation setting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7) Study performance of matrix-factorization model on real world dataset "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
